{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование Panphon, Epitran и разработанного алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные PanPhon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/Stoneberry/Desktop/курсач/4/test/Без названия/Лист 2-Tаблица 1.csv', 'r', encoding='utf-8') as f:\n",
    "    panphon_test = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ˈspiːkə', 'ˈlɪtərɪtʃə'],\n",
       " ['ədˈvaɪzə', 'ˈsabstəns'],\n",
       " ['θɔːt', 'swiːp'],\n",
       " ['neɪm', 'ˈbjuːtɪ'],\n",
       " ['ɪnˈkɔːpərɪt', 'baɪ'],\n",
       " ['faɪn', 'pəʊz'],\n",
       " ['rekəˈmend', 'smɑːt'],\n",
       " ['anˈfɔːtʃʊnətlɪ', 'ˈhandrəd'],\n",
       " ['ˈneɪkɪd', 'əˈkrɔs'],\n",
       " ['rɪˈlɪdʒəs', 'ɔv']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panphon_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(panphon_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные Epitran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/Stoneberry/Desktop/курсач/4/test/rus/Лист 1-Tаблица 1.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    epitran_test = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['передразнить', 'pʲɪrʲɪdrɒˈzʲnʲitʲ'],\n",
       " ['задирать', 'zədʲɪˈratʲ'],\n",
       " ['моська', 'ˈmosʲkə'],\n",
       " ['рыбак', 'rɨˈbak'],\n",
       " ['повозить', 'pəvɒˈzʲitʲ'],\n",
       " ['стоптать', 'stɒˈptatʲ'],\n",
       " ['евнух', 'ˈjevnʊx'],\n",
       " ['мессианский', 'mʲɪsʲ(ː)ɪˈanskʲɪɪ̯'],\n",
       " ['примитивно', 'prʲɪmʲɪˈtʲivnə'],\n",
       " ['проторчать', 'prətɒrˈt͡ɕatʲ']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epitran_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epitran_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panphon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panphon, panphon.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = panphon.distance.Distance()\n",
    "ft = panphon.FeatureTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка поиска расстояния"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один запуск на всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 193 ms, sys: 4.81 ms, total: 197 ms\n",
      "Wall time: 197 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for line in panphon_test:\n",
    "    dst.hamming_feature_edit_distance(line[0], line[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 запусков на всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Время в секундах: 0.21241527349926764'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    start = timer()\n",
    "    for line in panphon_test:\n",
    "        dst.hamming_feature_edit_distance(line[0], line[-1])\n",
    "    end = timer()\n",
    "    all_.append(end - start)\n",
    "\n",
    "'Время в секундах: ' + str(np.mean(all_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка сопоставления символам фонетических признаков "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один запуск на всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 88 ms, sys: 2.1 ms, total: 90.1 ms\n",
      "Wall time: 92.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for line in panphon_test:\n",
    "    ft.word_fts(line[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 запусков на всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Время в секундах: 0.0897408826330211'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    start = timer()\n",
    "    for line in panphon_test:\n",
    "        ft.word_fts(line[0])\n",
    "    end = timer()\n",
    "    all_.append(end - start)\n",
    "\n",
    "'Время в секундах: ' + str(np.mean(all_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epitran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import epitran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один запуск на всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 ms, sys: 3.36 ms, total: 17.7 ms\n",
      "Wall time: 32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for line in epitran_test:\n",
    "    epi.transliterate(line[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 запусков на всех данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Время в секундах: 0.01537087923186482'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi = epitran.Epitran('rus-Cyrl')\n",
    "    \n",
    "all_ = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    start = timer()\n",
    "    for line in epitran_test:\n",
    "        epi.transliterate(line[0])\n",
    "    end = timer()\n",
    "    all_.append(end - start)\n",
    "\n",
    "'Время в секундах: ' + str(np.mean(all_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разработанный алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import copy\n",
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def open_json(file):\n",
    "    \"\"\"\n",
    "    Открывает json файлы\n",
    "    \"\"\"\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Класс для автоматического анализа звуков\n",
    "    \"\"\"\n",
    "    def __init__(self, value=''):\n",
    "        self.previous = None\n",
    "        self.vector = value\n",
    "        self.value = value\n",
    "        self.affr = False\n",
    "        self.next = None\n",
    "        self.dift = False\n",
    "        self.dia = {}\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Функция удаляет все знаки препинания\n",
    "    \"\"\"\n",
    "    \n",
    "    global dia\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', dia))\n",
    "    return text\n",
    "\n",
    "\n",
    "def truncate(n, decimals=0):\n",
    "    \"\"\"\n",
    "    Функция для сокращения символов после запятой\n",
    "    \"\"\"\n",
    "    multiplier = 10 ** decimals\n",
    "    return int(n * multiplier) / multiplier\n",
    "\n",
    "\n",
    "def type_letter(item, vows, cons):\n",
    "\n",
    "    \"\"\"\n",
    "    Функция, которая определяет тип звука: гласный / согласный\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(item, list):\n",
    "        if isinstance(item[0], str): return type_letter(item[0], vows, cons)\n",
    "        elif isinstance(item[0], tuple):\n",
    "            if item[0][4] == '+': return 'vow'\n",
    "            elif item[0][4] == '-': return 'cons'\n",
    "    \n",
    "    elif item in vows: return 'vow'\n",
    "    elif item in cons: return 'cons'\n",
    "    \n",
    "    return 'None'\n",
    "\n",
    "\n",
    "def mean(a, b):\n",
    "    \"\"\"\n",
    "    Функция для расчета среднего значения\n",
    "    \"\"\"\n",
    "    return (a + b)/ 2\n",
    "\n",
    "\n",
    "def no(a, b):\n",
    "    \"\"\"\n",
    "    Функция для отсутсвия нормализации\n",
    "    \"\"\"\n",
    "    return 1\n",
    "\n",
    "\n",
    "json_paths = ['/Users/Stoneberry/Desktop/курсач/4/diacrit.json',\n",
    "              '/Users/Stoneberry/Desktop/курсач/4/cons.json',\n",
    "              '/Users/Stoneberry/Desktop/курсач/4/vows.json']\n",
    "\n",
    "with open('/Users/Stoneberry/Desktop/курсач/4/regs.txt', 'r', encoding='utf-8') as f:\n",
    "    reg_all_sounds, reg_comb, dia = f.readlines()\n",
    "    reg_all_sounds, reg_comb, dia = [reg_all_sounds[:-1], reg_comb[:-1], dia[:-1]]\n",
    "\n",
    "\n",
    "diacrit, cons, vows = [open_json(i) for i in json_paths]\n",
    "normal_func = {'mean': mean, 'max': max, 'min': min, False: no}\n",
    "pattern1 = re.compile(reg_comb)\n",
    "pattern2 = re.compile(reg_all_sounds)\n",
    "\n",
    "\n",
    "\n",
    "class PhoneticAlgorithmIPA:\n",
    "    \n",
    "    def __init__(self):\n",
    " \n",
    "        self.default_settings()\n",
    "\n",
    "\n",
    "    def default_settings(self):\n",
    "\n",
    "        self.feature_table = open_json('/Users/Stoneberry/Desktop/курсач/4/ftable.json')\n",
    "        self.column_index = open_json('/Users/Stoneberry/Desktop/курсач/4/index_column.json')\n",
    "        self.distance_matrix = open_json('/Users/Stoneberry/Desktop/курсач/4/non_ls_dist.json')\n",
    "        self.row = open_json('/Users/Stoneberry/Desktop/курсач/4/rows.json')\n",
    "    \n",
    "        self.feature = {}\n",
    "\n",
    "\n",
    "    def combination_splitter(self, word):\n",
    "        '''\n",
    "        Готовит строку к анализу, заменяет комбинации символов\n",
    "        '''\n",
    "        word = clean(word)\n",
    "        length = len(word)\n",
    "        res = re.findall(pattern1, word)\n",
    "\n",
    "        if res != []:\n",
    "            word = re.sub(pattern1, '@', word)\n",
    "        word  = word[::-1] + '#'\n",
    "   \n",
    "        return word, res, length\n",
    "\n",
    "\n",
    "    def dia_cond1(self, current, vows, cons, step, value):\n",
    "\n",
    "        a = type_letter(current.value, vows, cons) == 'vow'\n",
    "        b = current.previous is not None\n",
    "\n",
    "        if a and b:\n",
    "            c = type_letter(current.previous.value, vows, cons) == 'vow'\n",
    "            d = not current.previous.dia.get('stress')\n",
    "            e = not current.previous.dia.get('secondaty stress')\n",
    "            f = isinstance(current.previous.value, list) and len(current.previous.value) < 3\n",
    "            j = not isinstance(current.previous.value, list)\n",
    "            \n",
    "            if c and d and e:\n",
    "                if f or j:\n",
    "                    current.affr = True\n",
    "\n",
    "        return current\n",
    "\n",
    "\n",
    "    def dia_applier(self, current, step, vows, cons):\n",
    "        \n",
    "        if isinstance(current.value, list): return current.vector\n",
    "\n",
    "        if current.dia != {}:\n",
    "        \n",
    "##            vector = copy.copy(self.feature_table[current.value])\n",
    "\n",
    "            for value in current.dia:\n",
    "    \n",
    "                current.vector[self.column_index[value]] = current.dia[value]\n",
    "\n",
    "                if step == 0 and value == 'syllabic' and current.dia[value] == '-':\n",
    "                    current = self.dia_cond1(current, vows, cons, step, value)\n",
    "\n",
    "        current.vector = tuple(current.vector)\n",
    "                                \n",
    "        return current.vector\n",
    "    \n",
    "\n",
    "    def add_value(self, current, answer, letter, step, vows, cons):\n",
    "\n",
    "            \n",
    "        answer.append(current.vector)\n",
    "        cur = current\n",
    "        \n",
    "        if current.next is None:\n",
    "            current.next = Node()\n",
    "            \n",
    "        current = current.next\n",
    "        current.previous = cur\n",
    "\n",
    "        return current\n",
    "\n",
    "\n",
    "    def post_diacrit(self, index, length, current, value, letter):\n",
    "\n",
    "        if index == length - 1: raise ValueError\n",
    "\n",
    "        if current.value == '':\n",
    "            if letter == '̯': current.dift = True\n",
    "            current.dia = {**current.dia, **value[1]}\n",
    "            \n",
    "        else:\n",
    "            if current.next is None: current.next = Node()\n",
    "            if letter == '̯': current.next.dift = True\n",
    "            current.next.dia = {**current.next.dia , **value[1]}\n",
    "        \n",
    "        return current\n",
    "\n",
    "\n",
    "    def between_diacrit(self, index, length, current, step):\n",
    "\n",
    "        if 0 < index != length - 1:\n",
    "                    \n",
    "            if current.next is None: current.next = Node()\n",
    "            \n",
    "            current.next.affr = True\n",
    "                        \n",
    "            if isinstance(current.value, str):\n",
    "                current.vector = self.dia_applier(current, step, vows, cons)\n",
    "                current.vector = [current.vector]\n",
    "                current.value = [current.value]\n",
    "                current.dift = [current.dift]\n",
    "\n",
    "        else: raise ValueError\n",
    "\n",
    "        return current\n",
    "\n",
    "\n",
    "    def diacritics(self, letter, index, length, current, step):\n",
    "\n",
    "        value = diacrit[letter] # 'ⁿ': ['post', {'nasal': '+'}]\n",
    "\n",
    "        if value[0] == 'post':\n",
    "            current = self.post_diacrit(index, length, current, value, letter)\n",
    "\n",
    "        elif value[0] == 'pre':\n",
    "            if current.value == '': raise ValueError\n",
    "            current.dia = {**current.dia, **value[1]}\n",
    "\n",
    "        elif value[0] == 'between':\n",
    "            current = self.between_diacrit(index, length, current, step)\n",
    "        return current\n",
    "\n",
    "\n",
    "    def stress_number(self, length, word, index, number, current):\n",
    "     \n",
    "        v = 'The stress is presented incorrectly'\n",
    "        \n",
    "        if number == 0: raise ValueError(v)\n",
    "            \n",
    "        if length-1-index < number+1 or word[index+1] not in ('_', '='):\n",
    "            raise ValueError(v)\n",
    "            \n",
    "        if word[index+1] == '_': typ = 'main'\n",
    "        elif word[index+1] == '=': typ = 'side'\n",
    "\n",
    "        return [number, number, typ]\n",
    "\n",
    "\n",
    "    def stress_app(self, letter, step, current, answer, vows, cons):\n",
    "\n",
    "        if type_letter(current.value, vows, cons) != 'vow':\n",
    "            raise ValueError('A non vowel element is under stress')\n",
    "            \n",
    "        if step[0] == step[1] and step[0] != 1:\n",
    "            current.value = [current.value]\n",
    "            current.vector = [current.vector]\n",
    "            current.dift = [current.dift]\n",
    "    \n",
    "        elif step[0] != step[1]:\n",
    "            current.value = current.previous.value + [current.value]\n",
    "            current.vector = current.previous.vector + [current.vector]\n",
    "            current.dift = current.previous.dift + [current.dift]\n",
    "            current.previous = current.previous.previous\n",
    "            answer.pop()\n",
    "            \n",
    "        if step[0] == 1: step = 0\n",
    "        else: step[0] -= 1\n",
    "\n",
    "        return step\n",
    "\n",
    "\n",
    "    def affricate(self, current, answer, vows, cons):\n",
    "  \n",
    "        current.vector = [current.vector]\n",
    "        current.value = [current.value]\n",
    "        current.dift = [current.dift]\n",
    "        \n",
    "        if not isinstance(current.previous.value, list):\n",
    "            current.previous.value = [current.previous.value]\n",
    "            current.previous.vector = [current.previous.vector]\n",
    "            current.previous.dift = [current.previous.dift]\n",
    "            \n",
    "        current.vector += current.previous.vector\n",
    "        current.value += current.previous.value\n",
    "        current.dift += current.previous.dift\n",
    "        \n",
    "        if len({type_letter(i, vows, cons) for i in current.value}) != 1:\n",
    "            raise ValueError('All values should be have the same type')\n",
    "            \n",
    "        current.previous = current.previous.previous\n",
    "        answer.pop()\n",
    "        return current\n",
    "\n",
    "\n",
    "    def digit_rule(self, letter, step, current, answer, vows, cons):\n",
    "\n",
    "        if step != 0:\n",
    "            if step[0] != 1: raise ValueError('The stress is presented incorrectly')\n",
    "            \n",
    "        current, step = self.letter_parser(step, current, '', answer, vows, cons)\n",
    "\n",
    "        return current, step\n",
    "\n",
    "\n",
    "\n",
    "    def dia_cond2(self, current, vows, cons):\n",
    "\n",
    "        if not current.dia.get('syllabic') and current.previous is not None:\n",
    "\n",
    "            a = type_letter(current.previous.value, vows, cons) == 'vow'\n",
    "            a0 = current.previous.dia.get('syllabic') == '-'\n",
    "            b = not current.previous.dia.get('stress')\n",
    "            b1 = not current.previous.dia.get('secondaty stress')\n",
    "            c = isinstance(current.previous.value, list) and  False not in current.previous.dift\n",
    "            d = not isinstance(current.previous.value, list)\n",
    "\n",
    "            if a and a0 and b and b1:\n",
    "                if c or d:\n",
    "                    current.affr = True\n",
    "        return current\n",
    " \n",
    "    \n",
    "\n",
    "    def letter_parser(self, step, current, letter, answer, vows, cons, dig=False):\n",
    "\n",
    "        if step != 0: \n",
    "            if step[-1] == 'main': current.dia['stress'] = '+'\n",
    "            else: current.dia['second stress'] = '+'\n",
    "\n",
    "        if current.value != '':\n",
    "            current.vector = self.dia_applier(current, step, vows, cons)\n",
    "\n",
    "            if step == 0 and type_letter(current.value, vows, cons) == 'vow':\n",
    "                current = self.dia_cond2(current, vows, cons)\n",
    "\n",
    "            if step != 0:\n",
    "                step = self.stress_app(letter, step, current, answer, vows, cons)\n",
    "\n",
    "            if current.affr:\n",
    "                current = self.affricate(current, answer, vows, cons)\n",
    "            \n",
    "            current = self.add_value(current, answer, letter, step, vows, cons)\n",
    "\n",
    "        if letter not in ('#', ''): \n",
    "            current.value = letter\n",
    "            current.vector = copy.copy(self.feature_table[letter])\n",
    "        \n",
    "        return current, step\n",
    "\n",
    "\n",
    "    def transcription_splitter(self, word, diacrit, vows, cons):\n",
    "\n",
    "        if word == '': return ''\n",
    "\n",
    "        word, replacements, length = self.combination_splitter(word)\n",
    "        \n",
    "        answer = []\n",
    "        current = Node()\n",
    "        step, index_replace = 0, 0\n",
    "\n",
    "        for index, letter in enumerate(word):\n",
    "\n",
    "            if letter == '@':\n",
    "                letter = replacements[index_replace]\n",
    "                index_replace += 1\n",
    "\n",
    "            if letter in ('_', '='): continue\n",
    "\n",
    "            if letter.isdigit():\n",
    "                if current.value != '':\n",
    "                    current, step = self.digit_rule(letter, step, current, answer, vows, cons)\n",
    "                step = self.stress_number(length, word, index, int(letter), current)\n",
    "\n",
    "            elif letter in diacrit:\n",
    "                current = self.diacritics(letter, index, length, current, step)\n",
    "\n",
    "            elif letter in self.row or letter == '#':\n",
    "                current, step = self.letter_parser(step, current, letter, answer, vows, cons)\n",
    "            \n",
    "            else: raise ValueError('Wrong value: {}'.format(letter))\n",
    "\n",
    "        return answer[::-1]\n",
    "\n",
    "\n",
    "## --------------------------------------------------------\n",
    "\n",
    "    def sound_dist(self, a, b):\n",
    "\n",
    "        similar, common, uncommon = 0, 0, 0\n",
    "        \n",
    "        for index, item in enumerate(a): \n",
    "    \n",
    "            if item == b[index] and item != '0':\n",
    "                common += 1\n",
    "                similar += 1\n",
    "    \n",
    "            elif item != b[index]:\n",
    "                if item == '0' or b[index] == '0': uncommon += 1\n",
    "                else: common += 1\n",
    "            \n",
    "        dist = 1 - (similar / (common + (uncommon * 2)))\n",
    "        return dist\n",
    "\n",
    "\n",
    "    def different_length(self, a, len_a, b, len_b):\n",
    "\n",
    "        res = []\n",
    "\n",
    "        if len_a < len_b:\n",
    "            a, b = b, a\n",
    "            len_a, len_b = len_b, len_a\n",
    "\n",
    "        for i in a:\n",
    "            r = [self.sound_dist(i, l) for l in b]\n",
    "            res.append(min(r))\n",
    "\n",
    "        ans = sum(sorted(res)[:min(len_a, len_b)])\n",
    "\n",
    "    \n",
    "        return ans + len_a - len_b\n",
    "\n",
    "\n",
    "    def equal_length(self, a, b):\n",
    "\n",
    "        res = [self.sound_dist(it, b[ind]) for ind, it in enumerate(a)]\n",
    "\n",
    "        return sum(res)\n",
    "    \n",
    "    \n",
    "    def dist_affr(self, a, b):\n",
    "\n",
    "        len_a, len_b = len(a), len(b)\n",
    "\n",
    "        if len_a != len_b:\n",
    "            return self.different_length(a, len_a, b, len_b)\n",
    "    \n",
    "        return self.equal_length(a, b)\n",
    "        \n",
    "    \n",
    "    def phone_dist(self, a, b):\n",
    "        \n",
    "        if isinstance(a, list) and isinstance(b, list):\n",
    "            return self.dist_affr(a, b)\n",
    "        \n",
    "        if isinstance(a, list) and not isinstance(b, list):\n",
    "            return self.dist_affr(a, [b])\n",
    "        \n",
    "        if isinstance(b, list):\n",
    "            return self.dist_affr([a], b)\n",
    "        \n",
    "        return self.sound_dist(a, b)\n",
    "    \n",
    "    \n",
    "    def lev_distance(self, a, b):\n",
    "    \n",
    "        # Первыми - строчки \n",
    "        # столбики - слово b\n",
    "   \n",
    "        dis = [[0]* (len(b)+1) for _ in range(len(a)+1)]\n",
    "        size = (len(b)+1) * (len(a)+1)\n",
    "        i, row, col = 0, 0, 0\n",
    "        \n",
    "        while i < size:\n",
    "          \n",
    "            if row == 0:\n",
    "                if col != 0:\n",
    "                    dis[row][col] = dis[row][col-1] + 1\n",
    "\n",
    "            elif col == 0:\n",
    "                if row != 0:\n",
    "                    dis[row][col] = dis[row - 1][col] + 1\n",
    "            \n",
    "            elif row > 2 and col > 2 and a[row-1] == b[col-2] and a[row-2] == b[col-1]:\n",
    "                dis[row][col] = dis[row - 3][col - 3] + 1\n",
    "             \n",
    "            else:\n",
    "                dis[row][col] = min([dis[row][col - 1] + 1,  # левый \n",
    "                                    dis[row - 1][col - 1] + self.phone_dist(a[row-1], b[col-1]), # диаг               \n",
    "                                    dis[row - 1][col] + 1]) # верхний\n",
    "\n",
    "            col += 1\n",
    "            i += 1  \n",
    "\n",
    "            if col == len(b) + 1:\n",
    "                col = 0\n",
    "                row += 1\n",
    "        \n",
    "        return dis[len(a)][len(b)]\n",
    "\n",
    "## --------------------------------------------------------\n",
    "\n",
    "    def check_data(self, data, normalize):\n",
    "\n",
    "        global diacrit, vows, cons\n",
    "    \n",
    "        dists = []\n",
    "        \n",
    "        for line in data:\n",
    "    \n",
    "            if len(line) != 2:\n",
    "                raise ValueError('Wrong row number. Check your delimiter')\n",
    "            \n",
    "            if line[0] == line[1]: dist = 0\n",
    "            else:\n",
    "                a = self.transcription_splitter(line[0], diacrit, vows, cons)\n",
    "                b = self.transcription_splitter(line[1], diacrit, vows, cons)\n",
    "                \n",
    "                if a == '': dist = len(b)\n",
    "                if b == '': dist = len(a)\n",
    "                else: dist = self.lev_distance(a, b)\n",
    "                    \n",
    "                dist /= normal_func.get(normalize)(len(a), len(b))\n",
    "                \n",
    "            dists.append(dist)\n",
    "          #  print(line, dist)\n",
    "\n",
    "        return dists\n",
    "\n",
    "\n",
    "    def phonetic_distance(self, path, delimiter=';', typ='Non LS', total_dist=False,\n",
    "                          irrelevant_features=[], normalize=False):\n",
    "  \n",
    "        if not path.endswith('.csv'):\n",
    "            raise ValueError('Incorrect file type. It should be csv')\n",
    "            \n",
    "        if not os.path.isfile(path):\n",
    "            raise ValueError('Incorrect file path')\n",
    "            \n",
    "        if typ not in ('LS', 'Non LS'):\n",
    "            raise ValueError('Incorrect type argument')\n",
    "            \n",
    "        if not normal_func.get(normalize):\n",
    "            raise ValueError('Incorrect normalization argument')\n",
    "            \n",
    "        if not isinstance(irrelevant_features, list):\n",
    "            raise ValueError('Wrong irrelevant_features data type')\n",
    "            \n",
    "        if not isinstance(total_dist, bool):\n",
    "            raise ValueError('total_dist can only be True or False')\n",
    "        \n",
    "        if delimiter == '':\n",
    "            raise ValueError('Delimiter should be filled')\n",
    "        \n",
    "        with open(path, 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "            data = list(reader)\n",
    "\n",
    "        if typ == 'LS': self.ls_dist_matrix(data, irrelevant_features)\n",
    "        \n",
    "        elif irrelevant_features != []:\n",
    "            raise ValueError('If you want to delete irrelevant features, use \"LS\" type!')\n",
    "    \n",
    "        dist = self.check_data(data, normalize)\n",
    "        \n",
    "        return dist \n",
    "    \n",
    "\n",
    "    def stressed(self, line):\n",
    "    \n",
    "        reg2 = '.{%s}(?:_|=)%s'\n",
    "    \n",
    "        n = re.findall('(?:_|=)[1-9]', line)\n",
    "    \n",
    "        for i in n:\n",
    "            le = i[-1]\n",
    "            line = re.sub(reg2%(le, le), '*' * (int(le) + 2), line)\n",
    "    \n",
    "        return line\n",
    "    \n",
    "    \n",
    "    def right_part(self, index, len_right, line, right_rule, word, cons_u, vows_u):\n",
    "    \n",
    "        global cons, vows\n",
    "    \n",
    "        if right_rule == '': return True\n",
    "\n",
    "        idx = index + 1\n",
    "        length = len(line) - 1\n",
    "\n",
    "        while len_right > 0:\n",
    "        \n",
    "            if idx > length:  break\n",
    "    \n",
    "            if line[idx] in ('_', '=') or line[idx].isdigit():\n",
    "                idx += 1\n",
    "\n",
    "            else:\n",
    "            \n",
    "                if right_rule[-len_right] in self.feature_table:\n",
    "                    if right_rule[-len_right] in vows_u or right_rule[-len_right] in cons_u:\n",
    "                        l = line\n",
    "                    else: l = word \n",
    "                    #l = word\n",
    "                else: l = line\n",
    "            \n",
    "                if right_rule[-len_right] == '@':\n",
    "                    if l[idx] not in vows_u and word[idx] not in vows:\n",
    "                        return False\n",
    "            \n",
    "                elif right_rule[-len_right] == '$':\n",
    "                    if l[idx] not in cons_u and word[idx] not in cons: \n",
    "                        return False\n",
    "                \n",
    "                elif right_rule[-len_right] != l[idx]:\n",
    "                    return False\n",
    "\n",
    "                idx += 1\n",
    "                len_right -= 1\n",
    "\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def left_part(self, index, len_left, line, left_rule, word, cons_u, vows_u):\n",
    "    \n",
    "        global cons, vows\n",
    "    \n",
    "        if left_rule == '': return True\n",
    "\n",
    "        idx = index - 1\n",
    "\n",
    "        while len_left > 0:\n",
    "    \n",
    "            if idx < 0: break\n",
    "    \n",
    "            if line[idx] in ('_', '=') or line[idx].isdigit():\n",
    "                idx -= 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                if left_rule[len_left-1] in self.feature_table:\n",
    "                    if left_rule[len_left-1] in vows_u or left_rule[len_left-1] in cons_u:\n",
    "                        l = line\n",
    "                    else: l = word \n",
    "                    \n",
    "                else: l = line\n",
    "        \n",
    "                if left_rule[len_left-1] == '@':\n",
    "                    if l[idx] not in vows_u and word[idx] not in vows:\n",
    "                        return False\n",
    "            \n",
    "                elif left_rule[len_left-1] == '$':\n",
    "                    if l[idx] not in cons_u and word[idx] not in cons: \n",
    "                        return False\n",
    "            \n",
    "                elif left_rule[len_left-1] != l[idx]:\n",
    "                    return False\n",
    "   \n",
    "            \n",
    "                idx -= 1\n",
    "                len_left -= 1\n",
    "\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def rule_finder(self, letter, rules_dict, rules):\n",
    "        \n",
    "        rule = rules_dict.get(letter)\n",
    "        \n",
    "        if rule:\n",
    "            rules += rule\n",
    "        return rules\n",
    "    \n",
    "    \n",
    "    def rule_applier(self, rules_dict, word, cons_u=[], vows_u=[]):\n",
    "        '''\n",
    "        ДОБАВИТЬ,ЧТО ЕСЛИ ЭЛЕМЕНТ ЕСТЬ В МФА, ТОГДА СМОТРАТЬ НА КОНТЕКСТ В RES\n",
    "    \n",
    "        МОЖНО ГУЛЯТЬ ПО ПРАВИЛАМ ПОКА НЕЧЕГО БУДЕТ МЕНЯТЬ \n",
    "    \n",
    "        @_ А реализуется как В в позиции перед гласным\n",
    "        &_& А реализуется как В в позиции между двумя согласными\n",
    "        '''\n",
    "\n",
    "        res = [''] * len(word)\n",
    "        count = 0\n",
    "    \n",
    "        while True:\n",
    "            \n",
    "            for index, letter in enumerate(word):\n",
    "  \n",
    "                ans = letter\n",
    "                line = word\n",
    "                rules = []\n",
    "        \n",
    "                if letter not in ('_', '=') or not letter.isdigit():\n",
    "                \n",
    "                    rules = self.rule_finder(letter, rules_dict, rules)\n",
    "                    if letter in vows_u:\n",
    "                        rules = self.rule_finder('@', rules_dict, rules)\n",
    "                    if letter in cons_u:\n",
    "                        rules = self.rule_finder('&', rules_dict, rules)\n",
    "                    \n",
    "                   # rule2 = rules_dict.get(letter)\n",
    "                 #   if rule2: rules += rule2\n",
    "                    \n",
    "                  #  if letter in vows_u:\n",
    "                  #      rule2 = rules_dict.get('@')\n",
    "                  #  if letter in vows_u:\n",
    "                  #      rule2 = rules_dict.get('&') \n",
    "                        \n",
    "                   # if rules\n",
    "        \n",
    "                    if rules != []:\n",
    "                \n",
    "                        for value, rule in rules:\n",
    "                        \n",
    "                            if rule == '': ans = value\n",
    "                        \n",
    "                            elif '_' in rule:\n",
    "                                if '*' in rule: line = self.stressed(word)\n",
    "                \n",
    "                                left, right = rule.split('_')\n",
    "                \n",
    "                                left = self.left_part(index, len(left), line, left, res, cons_u, vows_u)\n",
    "                                right = self.right_part(index, len(right), line, right, res, cons_u, vows_u)\n",
    "                                \n",
    "                                if left and right:\n",
    "                                    count += 1\n",
    "                                    ans = value\n",
    "                            else:\n",
    "                                raise ValueError('Wrong rule: {}'.format(rule))\n",
    "       \n",
    "                res[index] = ans\n",
    " \n",
    "            if count == 0: break\n",
    "            else: \n",
    "                count = 0\n",
    "                word = res\n",
    "\n",
    "        return ''.join(res[1:-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def rule_collector(self, rules_dict):\n",
    "    \n",
    "        d = defaultdict(list)\n",
    "    \n",
    "        for line in rules_dict:\n",
    "            \n",
    "            if len(line) != 3:\n",
    "                raise ValueError('There have to be 3 columns')\n",
    "                \n",
    "            d[line[0]].append([line[1], line[2]])\n",
    "    \n",
    "        return d\n",
    "    \n",
    "    \n",
    "    def phonetic_transformer(self, data_path, rules_path, delimiter=';', typ='Non LS', irrelevant_features=[],\n",
    "                             normalize=False, total_dist=False, cons_u=[], vows_u=[]):\n",
    "    \n",
    "        \"\"\"\n",
    "        Чувствителен к регистру\n",
    "        \"\"\"\n",
    "    \n",
    "        if not data_path.endswith('.csv') or not rules_path.endswith('.csv'):\n",
    "            raise ValueError('Incorrect data type. It should be csv')\n",
    "            \n",
    "        if not os.path.isfile(data_path) or not os.path.isfile(rules_path):\n",
    "            raise ValueError('Incorrect file path')\n",
    "            \n",
    "        if not normal_func.get(normalize):\n",
    "            raise ValueError('Incorrect normalization argument')\n",
    "            \n",
    "        if typ not in ('LS', 'Non LS'):\n",
    "            raise ValueError('Incorrect type argument')\n",
    "            \n",
    "        if not isinstance(irrelevant_features, list):\n",
    "            raise ValueError('Wrong irrelevant_features data type')\n",
    "            \n",
    "        if not isinstance(total_dist, bool):\n",
    "            raise ValueError('total_dist can only be True or False')\n",
    "        \n",
    "        if delimiter == '':\n",
    "            raise ValueError('Delimiter should be filled')\n",
    "            \n",
    "        if not isinstance(vows_u, list):\n",
    "            raise ValueError('Vows should be list')\n",
    "            \n",
    "        if not isinstance(cons_u, list):\n",
    "            raise ValueError('Cons should be list')\n",
    "            \n",
    "        if vows_u != [] and {isinstance(i, str) for i in vows_u} != {True}:\n",
    "            raise ValueError('Incrorrect vows_u type')\n",
    "            \n",
    "        if cons_u != [] and {isinstance(i, str) for i in cons_u} != {True}:\n",
    "            raise ValueError('Incrorrect vows_u type')\n",
    "    \n",
    "        with open(rules_path, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "            rules = list(reader)\n",
    "    \n",
    "        with open(data_path, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "            data = list(reader)\n",
    "\n",
    "        rules_dict = self.rule_collector(rules)\n",
    "        \n",
    "        res = []\n",
    "        \n",
    "        for line in data:\n",
    "            \n",
    "            l = self.rule_applier(rules_dict, '#' + clean(line[0]) + '#', cons_u, vows_u)\n",
    "            r = self.rule_applier(rules_dict, '#' + clean(line[1]) + '#', cons_u, vows_u)\n",
    "            res.append((l, r))\n",
    "            \n",
    "        if typ == 'LS': self.ls_dist_matrix(res, irrelevant_features)\n",
    "        \n",
    "        elif typ == 'Non_LS' and irrelevant_features != []:\n",
    "            raise ValueError('If you want to delete irrelevant features, use \"LS\" type!')\n",
    "  \n",
    "        dist = self.check_data(res, normalize)\n",
    "        \n",
    "        if total_dist is True:\n",
    "            return dist, mean(total_dist)\n",
    "        return dist \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сопоставление элементам трансприпций векторов признаков "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один запуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 ms, sys: 149 µs, total: 7.23 ms\n",
      "Wall time: 7.16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for line in panphon_test:\n",
    "    ipa.transcription_splitter(line[0], diacrit, vows, cons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 запусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Время в секундах: 0.007276536353863776'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa = PhoneticAlgorithmIPA()\n",
    "\n",
    "all_ = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    start = timer()\n",
    "    for line in panphon_test:\n",
    "        ipa.transcription_splitter(line[0], diacrit, vows, cons)\n",
    "    end = timer()\n",
    "    all_.append(end - start)\n",
    "\n",
    "'Время в секундах: ' + str(np.mean(all_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Поиск расстояний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один запуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.9 ms, sys: 1.72 ms, total: 52.6 ms\n",
      "Wall time: 51.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "a = ipa.phonetic_distance('/Users/Stoneberry/Desktop/курсач/4/test/Без названия/Лист 2-Tаблица 1.csv',\n",
    "                          delimiter=';', typ='Non LS')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 запусков с открытием файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Время в секундах: 0.0544707239830459'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa = PhoneticAlgorithmIPA()\n",
    "\n",
    "all_ = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    start = timer()\n",
    "    a = ipa.phonetic_distance('/Users/Stoneberry/Desktop/курсач/4/test/Без названия/Лист 2-Tаблица 1.csv',\n",
    "                              delimiter=';', typ='Non LS')\n",
    "    end = timer()\n",
    "    all_.append(end - start)\n",
    "\n",
    "'Время в секундах: ' + str(np.mean(all_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 запусков без открытия файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Время в секундах: 0.05385899727549986'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa = PhoneticAlgorithmIPA()\n",
    "\n",
    "all_ = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    start = timer()\n",
    "    for line in panphon_test:\n",
    "        a = ipa.transcription_splitter(line[0], diacrit, vows, cons)\n",
    "        b = ipa.transcription_splitter(line[1], diacrit, vows, cons)\n",
    "        ipa.lev_distance(a, b)\n",
    "    end = timer()\n",
    "    all_.append(end - start)\n",
    "\n",
    "'Время в секундах: ' + str(np.mean(all_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Время в секундах: 0.008630379054869991'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipa = PhoneticAlgorithmIPA()\n",
    "\n",
    "\n",
    "rules = '/Users/Stoneberry/Desktop/курсач/4/test/rus/Лист 2-Tаблица 1.csv'\n",
    "\n",
    "\n",
    "with open(rules, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    rules = list(reader)\n",
    "\n",
    "rules_dict = ipa.rule_collector(rules)\n",
    "\n",
    "\n",
    "all_ = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    start = timer()\n",
    "    for i in epitran_test:\n",
    "        ipa.rule_applier(rules_dict, '#' + clean(i[0]) + '#' )\n",
    "    end = timer()\n",
    "    all_.append(end - start)\n",
    "\n",
    "'Время в секундах: ' + str(np.mean(all_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПИСЬМЕННОСТИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ara-Arab ben-Beng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_jap = {'お': [['o', '']],\n",
    "        'さ': [['sa', '']],\n",
    "        'ん': [['n', '']],\n",
    "        '父': [['tou', '']],\n",
    "        'サ': [['sa', '#_']],\n",
    "        'ポ': [['po', '']],\n",
    "        'ー': [['', '']],\n",
    "        'ト': [['to', '']]}\n",
    "\n",
    "rules_ev = {'א': [['ʔ', '']],\n",
    "            'ב': [['b', '']],\n",
    "            'ת': [['d', '']],\n",
    "            'מ': [['m', '']],\n",
    "            'י': [['j', '']],\n",
    "            'כ': [['k', '']],\n",
    "            'ה': [['h', '']]}\n",
    "\n",
    "rules_arm = {'հ': [['h', '']],\n",
    "             'ա': [['ɑ', '']],\n",
    "             'յ': [['j', '']],\n",
    "             'ր': [['r', '']],\n",
    "             'ի': [['i', '']],\n",
    "             'կ': [['k', '']],\n",
    "             'ջ': [['ʤ', '']],\n",
    "             'ց': [['tsʰ', '']],\n",
    "             'ո': [['o', '']],\n",
    "             'ւ': [['w', '']],\n",
    "             'թ': [['tʰ', '']],\n",
    "             'ն': [['n', '']]}\n",
    "\n",
    "rules_gr = {'მ': [['m', '']],\n",
    "            'ხ': [['χ', '']],\n",
    "            'ა': [['ɑ', '']],\n",
    "            'რ': [['r', '']],\n",
    "            'დ': [['d', '']],\n",
    "            'ჭ': [['t͡ʃʼ', '']],\n",
    "            'ე': [['ɛ', '']]}\n",
    "\n",
    "\n",
    "rules_ara = {'ا': [['а̄', '']],\n",
    "            'د': [['d', '']],\n",
    "            'ع': [['ʕ', '']],\n",
    "            'م': [['m', '']],\n",
    "            'ﺏ': [['b', '']],\n",
    "            'ِ': [['a', '']],\n",
    "            'ل': [['l', '']],}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# папа\n",
    "# опора\n",
    "\n",
    "jap = {'お父さん': 'otousan',\n",
    "     'サポート': 'sapoto'}\n",
    "\n",
    "ara = {'بَابَا': 'baba', \n",
    "       'الدعم': 'adʕam'}\n",
    "\n",
    "ev = {'אבא': 'aba', \n",
    "       'תמיכה': 'tmikha'}\n",
    "\n",
    "arm = {'հայրիկ': 'hayrik', \n",
    "       'աջակցություն': 'aʤaktsutyun'}\n",
    "\n",
    "gr = {'მხარდაჭერა': 'mχardat͡ʃʼɛra', \n",
    "       'მამა': 'mama'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa = PhoneticAlgorithmIPA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(data, rules_dict):\n",
    "    for i in data:\n",
    "        a = ipa.rule_applier(rules_dict, '#' + clean(i) + '#' )\n",
    "        print(i, data[i], a)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "お父さん otousan otousan\n",
      "サポート sapoto sapoto\n"
     ]
    }
   ],
   "source": [
    "foo(jap, rules_jap) # japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بَابَا baba بَа̄بَа̄\n",
      "الدعم adʕam а̄ldʕm\n"
     ]
    }
   ],
   "source": [
    "foo(ara, rules_ara) # arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "მხარდაჭერა mχardat͡ʃʼɛra mχɑrdɑt͡ʃʼɛrɑ\n",
      "მამა mama mɑmɑ\n"
     ]
    }
   ],
   "source": [
    "foo(gr, rules_gr) # gruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "հայրիկ hayrik hɑjrik\n",
      "աջակցություն aʤaktsutyun ɑʤɑktsʰowtʰjown\n"
     ]
    }
   ],
   "source": [
    "foo(arm, rules_arm) # armenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "אבא aba ʔbʔ\n",
      "תמיכה tmikha dmjkh\n"
     ]
    }
   ],
   "source": [
    "foo(ev, rules_ev) # evr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = epitran.Epitran('ara-Arab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ʃِiːn'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi.transliterate('شِين')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'بَа̄بَа̄'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('ِ', 'a', 'بَа̄بَа̄')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ʃِiːn\n",
      "\n",
      "CPU times: user 8.83 ms, sys: 2.27 ms, total: 11.1 ms\n",
      "Wall time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "ipa = PhoneticAlgorithmIPA()\n",
    "\n",
    "\n",
    "rules = '/Users/Stoneberry/Desktop/курсач/4/test/rus/Лист 2-Tаблица 1.csv'\n",
    "#rules = '/Users/Stoneberry/Desktop/курсач/4/test/arab/Лист 2-Tаблица 1.csv'\n",
    "\n",
    "with open(rules, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=';')\n",
    "    rules = list(reader)\n",
    "\n",
    "rules_dict = ipa.rule_collector(rules)\n",
    "\n",
    "\n",
    "all_ = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    start = timer()\n",
    "    for line in panphon_test:\n",
    "        a = ipa.transcription_splitter(line[0], diacrit, vows, cons)\n",
    "        b = ipa.transcription_splitter(line[1], diacrit, vows, cons)\n",
    "        ipa.lev_distance(a, b)\n",
    "    end = timer()\n",
    "    all_.append(end - start)\n",
    "\n",
    "'Время в секундах: ' + str(np.mean(all_))\n",
    "\n",
    "\n",
    "#ara = {'بَابَا': 'baba', \n",
    "#       'الدعم': 'adʕam'}\n",
    "\n",
    "#a = ipa.rule_applier(rules_dict, \"#\" + 'شِين' + '#' )\n",
    "\n",
    "#for i in data:\n",
    "#    a = ipa.rule_applier(rules_dict, '#' + clean(i[0]) + '#' )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
